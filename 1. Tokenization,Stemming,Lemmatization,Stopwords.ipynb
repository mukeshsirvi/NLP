{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768bb9cc",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7805ee",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3efa046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'is', 'introduced', 'in', '1956', 'but', 'it', 'got', 'popularity', 'recently', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "sent1=\"AI is introduced in 1956 but it got popularity recently.\"\n",
    "print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9814de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'self', 'Mukesh', 'Sirvi', '.', 'I', 'am', 'from', 'Pali', 'Rajasthan', '.']\n"
     ]
    }
   ],
   "source": [
    "sent2=\"My self Mukesh Sirvi. I am from Pali Rajasthan.\"\n",
    "print(word_tokenize(sent2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9269940",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2db213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI is introduced in 1956 but it got popularity recently.']\n",
      "['My self Mukesh Sirvi.', 'I am from Pali Rajasthan.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "print(sent_tokenize(sent1))\n",
    "print(sent_tokenize(sent2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518938e0",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2135def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai is introduced in 1956 but it got popularity recently.\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "print(ps.stem(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd05e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stem word is ai\n",
      "is stem word is is\n",
      "introduced stem word is introduc\n",
      "in stem word is in\n",
      "1956 stem word is 1956\n",
      "but stem word is but\n",
      "it stem word is it\n",
      "got stem word is got\n",
      "popularity stem word is popular\n",
      "recently stem word is recent\n",
      ". stem word is .\n"
     ]
    }
   ],
   "source": [
    "word1=word_tokenize(sent1)\n",
    "for w in word1:\n",
    "    print(\"{} stem word is {}\".format(w,ps.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbc9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My stem word is my\n",
      "self stem word is self\n",
      "Mukesh stem word is mukesh\n",
      "Sirvi stem word is sirvi\n",
      ". stem word is .\n",
      "I stem word is i\n",
      "am stem word is am\n",
      "from stem word is from\n",
      "Pali stem word is pali\n",
      "Rajasthan stem word is rajasthan\n",
      ". stem word is .\n"
     ]
    }
   ],
   "source": [
    "word2=word_tokenize(sent2)\n",
    "for w in word2:\n",
    "    print(\"{} stem word is {}\".format(w,ps.stem(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821aba17",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9dfe784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stem word is AI\n",
      "is stem word is is\n",
      "introduced stem word is introduced\n",
      "in stem word is in\n",
      "1956 stem word is 1956\n",
      "but stem word is but\n",
      "it stem word is it\n",
      "got stem word is got\n",
      "popularity stem word is popularity\n",
      "recently stem word is recently\n",
      ". stem word is .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lm=WordNetLemmatizer()\n",
    "for w in word1:\n",
    "    print(\"{} lemmatized word is {}\".format(w,lm.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db29522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait lemmatized word is wait\n",
      "waits lemmatized word is wait\n",
      "waiting lemmatized word is waiting\n",
      "waited lemmatized word is waited\n"
     ]
    }
   ],
   "source": [
    "sent3=\"wait waits waiting waited\"\n",
    "word3=word_tokenize(sent3)\n",
    "for w in word3:\n",
    "    print(\"{} lemmatized word is {}\".format(w,lm.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c23984",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be7ee65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is introduced in 1956 but it got popularity recently.\n",
      "['AI', 'introduced', '1956', 'got', 'popularity', 'recently', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words(\"english\")\n",
    "print(sent1)\n",
    "removed_stop_words=[]\n",
    "for w in word1:\n",
    "    if w not in stop_words:\n",
    "        removed_stop_words.append(w)\n",
    "print(removed_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd3b066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d3f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
